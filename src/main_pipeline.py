#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸­å›½ç–¾æ§ä¸­å¿ƒç›‘æµ‹æ•°æ®è‡ªåŠ¨åŒ–å¤„ç†æµç¨‹
ä»URLåˆ—è¡¨è‡ªåŠ¨ä¸‹è½½ã€è½¬æ¢ã€æå–æ•°æ®å¹¶æ›´æ–°åˆ°ä¸»æ•°æ®æ–‡ä»¶
"""

import os
import sys
import shutil
import subprocess
import argparse
from pathlib import Path
from datetime import datetime
import pandas as pd
import re


def run_command(cmd, description=""):
    """è¿è¡Œå‘½ä»¤å¹¶æ£€æŸ¥ç»“æœ"""
    print(f"\n{'='*60}")
    print(f"æ‰§è¡Œ: {description}")
    print(f"å‘½ä»¤: {' '.join(cmd)}")
    print(f"{'='*60}")
    
    result = subprocess.run(cmd, capture_output=True, text=True)
    
    if result.returncode != 0:
        print(f"âŒ é”™è¯¯: {description} å¤±è´¥")
        print(f"é”™è¯¯ä¿¡æ¯:\n{result.stderr}")
        return False
    
    print(result.stdout)
    if result.stderr:
        print(result.stderr)
    
    print(f"âœ… {description} å®Œæˆ")
    return True


def extract_reference_date_from_csv(csv_path):
    """ä»CSVæ–‡ä»¶ä¸­æå–reference_date"""
    try:
        df = pd.read_csv(csv_path, encoding='utf-8-sig')
        if 'reference_date' in df.columns and len(df) > 0:
            # è·å–ç¬¬ä¸€è¡Œçš„reference_date
            ref_date = df['reference_date'].iloc[0]
            if pd.notna(ref_date):
                return str(ref_date)
    except Exception as e:
        print(f"âš ï¸  ä»CSVæå–æ—¥æœŸå¤±è´¥: {e}")
    return None


def get_file_id_from_url(url):
    """ä»URLä¸­æå–æ–‡ä»¶IDï¼ˆå¦‚t20251015_312973ï¼‰"""
    match = re.search(r'(t\d{8}_\d+)', url)
    if match:
        return match.group(1)
    return None


def merge_to_main_data(new_csv, all_csv, covid_csv):
    """åˆå¹¶æ–°æ•°æ®åˆ°ä¸»æ•°æ®æ–‡ä»¶ï¼Œå¹¶æŒ‰æ—¥æœŸé™åºæ’åˆ—"""
    try:
        # è¯»å–æ–°æ•°æ®
        new_df = pd.read_csv(new_csv, encoding='utf-8-sig')
        print(f"ğŸ“Š æ–°æ•°æ®: {len(new_df)} è¡Œ")
        
        # å¤„ç†ä¸»æ•°æ®æ–‡ä»¶
        if os.path.exists(all_csv):
            all_df = pd.read_csv(all_csv, encoding='utf-8-sig')
            print(f"ğŸ“Š ç°æœ‰å…¨éƒ¨æ•°æ®: {len(all_df)} è¡Œ")
            
            # åˆå¹¶æ•°æ®ï¼ˆæ–°æ•°æ®åœ¨å‰ï¼‰
            combined_df = pd.concat([new_df, all_df], ignore_index=True)
            
            # å»é‡ï¼ˆä¿ç•™ç¬¬ä¸€æ¬¡å‡ºç°çš„ï¼Œå³æ–°æ•°æ®ä¼˜å…ˆï¼‰
            combined_df = combined_df.drop_duplicates(
                subset=['reference_date', 'target_end_date', 'pathogen'],
                keep='first'
            )
            
            # æŒ‰æ—¥æœŸé™åºæ’åˆ—
            combined_df['_sort_date'] = pd.to_datetime(combined_df['reference_date'], errors='coerce')
            combined_df = combined_df.sort_values(
                ['_sort_date', 'pathogen'], 
                ascending=[False, True]
            ).drop(columns=['_sort_date'])
            
            # ä¿å­˜
            combined_df.to_csv(all_csv, index=False, encoding='utf-8-sig')
            print(f"âœ… æ›´æ–°å…¨éƒ¨æ•°æ®: {len(combined_df)} è¡Œ -> {all_csv}")
        else:
            # å¦‚æœä¸»æ–‡ä»¶ä¸å­˜åœ¨ï¼Œç›´æ¥ä¿å­˜æ–°æ•°æ®
            new_df['_sort_date'] = pd.to_datetime(new_df['reference_date'], errors='coerce')
            new_df = new_df.sort_values(
                ['_sort_date', 'pathogen'], 
                ascending=[False, True]
            ).drop(columns=['_sort_date'])
            new_df.to_csv(all_csv, index=False, encoding='utf-8-sig')
            print(f"âœ… åˆ›å»ºå…¨éƒ¨æ•°æ®: {len(new_df)} è¡Œ -> {all_csv}")
        
        # å¤„ç†æ–°å† æ•°æ®æ–‡ä»¶
        covid_new_df = new_df[new_df['pathogen'].str.contains('æ–°å‹å† çŠ¶ç—…æ¯’', na=False)]
        print(f"ğŸ“Š æ–°å† ç—…æ¯’æ–°æ•°æ®: {len(covid_new_df)} è¡Œ")
        
        if os.path.exists(covid_csv):
            covid_df = pd.read_csv(covid_csv, encoding='utf-8-sig')
            print(f"ğŸ“Š ç°æœ‰æ–°å† æ•°æ®: {len(covid_df)} è¡Œ")
            
            # åˆå¹¶æ•°æ®
            combined_covid_df = pd.concat([covid_new_df, covid_df], ignore_index=True)
            
            # å»é‡
            combined_covid_df = combined_covid_df.drop_duplicates(
                subset=['reference_date', 'target_end_date', 'pathogen'],
                keep='first'
            )
            
            # æŒ‰æ—¥æœŸé™åºæ’åˆ—
            combined_covid_df['_sort_date'] = pd.to_datetime(combined_covid_df['reference_date'], errors='coerce')
            combined_covid_df = combined_covid_df.sort_values(
                '_sort_date', 
                ascending=False
            ).drop(columns=['_sort_date'])
            
            # ä¿å­˜
            combined_covid_df.to_csv(covid_csv, index=False, encoding='utf-8-sig')
            print(f"âœ… æ›´æ–°æ–°å† æ•°æ®: {len(combined_covid_df)} è¡Œ -> {covid_csv}")
        else:
            # å¦‚æœä¸»æ–‡ä»¶ä¸å­˜åœ¨ï¼Œç›´æ¥ä¿å­˜æ–°æ•°æ®
            if len(covid_new_df) > 0:
                covid_new_df['_sort_date'] = pd.to_datetime(covid_new_df['reference_date'], errors='coerce')
                covid_new_df = covid_new_df.sort_values(
                    '_sort_date', 
                    ascending=False
                ).drop(columns=['_sort_date'])
                covid_new_df.to_csv(covid_csv, index=False, encoding='utf-8-sig')
                print(f"âœ… åˆ›å»ºæ–°å† æ•°æ®: {len(covid_new_df)} è¡Œ -> {covid_csv}")
        
        return True
        
    except Exception as e:
        print(f"âŒ åˆå¹¶æ•°æ®å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    parser = argparse.ArgumentParser(description="ä¸­å›½ç–¾æ§ä¸­å¿ƒç›‘æµ‹æ•°æ®è‡ªåŠ¨åŒ–å¤„ç†æµç¨‹")
    parser.add_argument(
        "--url-file",
        default="config/url_surveillance_new.txt",
        help="URLåˆ—è¡¨æ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--pdf-server",
        default="http://10.22.16.132:8011",
        help="PDFè½¬MarkdownæœåŠ¡å™¨åœ°å€"
    )
    parser.add_argument(
        "--update-dir",
        default="update",
        help="æ›´æ–°æ–‡ä»¶å­˜æ”¾ç›®å½•"
    )
    parser.add_argument(
        "--all-csv",
        default="data/cncdc_surveillance_all.csv",
        help="å…¨éƒ¨æ•°æ®CSVæ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--covid-csv",
        default="data/cncdc_surveillance_covid19.csv",
        help="æ–°å† æ•°æ®CSVæ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--skip-download",
        action="store_true",
        help="è·³è¿‡ä¸‹è½½å’Œè½¬æ¢æ­¥éª¤ï¼ˆä»…ç”¨äºæµ‹è¯•ï¼‰"
    )
    
    args = parser.parse_args()
    
    # è·å–é¡¹ç›®æ ¹ç›®å½•
    root_dir = Path(__file__).parent.parent.absolute()
    os.chdir(root_dir)
    print(f"ğŸ“ å·¥ä½œç›®å½•: {root_dir}")
    
    # è¯»å–URLæ–‡ä»¶
    url_file = Path(args.url_file)
    if not url_file.exists():
        print(f"âŒ URLæ–‡ä»¶ä¸å­˜åœ¨: {url_file}")
        return 1
    
    with open(url_file, 'r', encoding='utf-8') as f:
        urls = [line.strip() for line in f if line.strip() and not line.startswith('#')]
    
    if not urls:
        print(f"âŒ URLæ–‡ä»¶ä¸ºç©º: {url_file}")
        return 1
    
    print(f"ğŸ“‹ æ‰¾åˆ° {len(urls)} ä¸ªURL")
    
    # å¤„ç†æ¯ä¸ªURL
    for idx, url in enumerate(urls, 1):
        print(f"\n{'#'*60}")
        print(f"å¤„ç† URL {idx}/{len(urls)}: {url}")
        print(f"{'#'*60}")
        
        # æå–æ–‡ä»¶ID
        file_id = get_file_id_from_url(url)
        if not file_id:
            print(f"âš ï¸  æ— æ³•ä»URLæå–æ–‡ä»¶IDï¼Œè·³è¿‡: {url}")
            continue
        
        print(f"ğŸ“ æ–‡ä»¶ID: {file_id}")
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        update_dir = Path(args.update_dir)
        temp_pdf_dir = update_dir / "pdf"
        temp_md_dir = update_dir / "md"
        temp_data_dir = update_dir / "data"
        
        temp_pdf_dir.mkdir(parents=True, exist_ok=True)
        temp_md_dir.mkdir(parents=True, exist_ok=True)
        temp_data_dir.mkdir(parents=True, exist_ok=True)
        
        pdf_file = temp_pdf_dir / f"{file_id}.pdf"
        md_file = temp_md_dir / f"{file_id}.md"
        csv_file = temp_data_dir / f"{file_id}.csv"
        
        if not args.skip_download:
            # æ­¥éª¤1: ä¸‹è½½ç½‘é¡µä¸ºPDF
            if not pdf_file.exists():
                cmd = [
                    "uv", "run", "python", "src/save_web_to_pdf.py",
                    url,
                    "-o", str(temp_pdf_dir),
                    "--format", "A1",
                    "--margin", "10mm",
                    "-c", "6",
                    "--wait-until", "load"
                ]
                if not run_command(cmd, "ä¸‹è½½ç½‘é¡µä¸ºPDF"):
                    print(f"âš ï¸  è·³è¿‡URL: {url}")
                    continue
            else:
                print(f"âœ“ PDFæ–‡ä»¶å·²å­˜åœ¨: {pdf_file}")
            
            # æ­¥éª¤2: è½¬æ¢PDFä¸ºMarkdown
            if not md_file.exists():
                cmd = [
                    "uv", "run", "python", "src/convert_pdf_to_md.py",
                    str(pdf_file),
                    "-o", str(temp_md_dir),
                    "--server", args.pdf_server,
                    "--lang", "ch",
                    "--backend", "pipeline",
                    "--parse-method", "auto",
                    "--formula-enable", "true",
                    "--table-enable", "true",
                    "--workers", "6",
                    "--timeout", "180"
                ]
                if not run_command(cmd, "è½¬æ¢PDFä¸ºMarkdown"):
                    print(f"âš ï¸  è·³è¿‡URL: {url}")
                    continue
            else:
                print(f"âœ“ Markdownæ–‡ä»¶å·²å­˜åœ¨: {md_file}")
            
            # æ­¥éª¤3: æå–æ•°æ®ä¸ºCSV
            if not csv_file.exists():
                cmd = [
                    "uv", "run", "python", "src/extract_surveillance_data.py",
                    str(md_file),
                    "-o", str(csv_file)
                ]
                if not run_command(cmd, "æå–ç›‘æµ‹æ•°æ®"):
                    print(f"âš ï¸  è·³è¿‡URL: {url}")
                    continue
            else:
                print(f"âœ“ CSVæ–‡ä»¶å·²å­˜åœ¨: {csv_file}")
        else:
            print("â­ï¸  è·³è¿‡ä¸‹è½½å’Œè½¬æ¢æ­¥éª¤")
        
        # æ­¥éª¤4: æå–reference_dateå¹¶åˆ›å»ºç›®æ ‡ç›®å½•
        print(f"\nğŸ“… æå–å‚è€ƒæ—¥æœŸ...")
        ref_date = extract_reference_date_from_csv(csv_file)
        
        if not ref_date:
            print(f"âš ï¸  æ— æ³•æå–reference_dateï¼Œä½¿ç”¨æ–‡ä»¶IDä½œä¸ºç›®å½•å")
            target_dir_name = file_id
        else:
            print(f"âœ… å‚è€ƒæ—¥æœŸ: {ref_date}")
            target_dir_name = ref_date
        
        # åˆ›å»ºç›®æ ‡ç›®å½•ç»“æ„
        target_dir = update_dir / target_dir_name
        target_pdf_dir = target_dir / "pdf"
        target_md_dir = target_dir / "md"
        target_csv_dir = target_dir / "csv"
        
        target_pdf_dir.mkdir(parents=True, exist_ok=True)
        target_md_dir.mkdir(parents=True, exist_ok=True)
        target_csv_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"ğŸ“ åˆ›å»ºç›®å½•ç»“æ„: {target_dir}")
        
        # æ­¥éª¤5: ç§»åŠ¨æ–‡ä»¶åˆ°ç›®æ ‡ç›®å½•
        target_pdf = target_pdf_dir / f"{file_id}.pdf"
        target_md = target_md_dir / f"{file_id}.md"
        target_csv = target_csv_dir / f"{file_id}.csv"
        
        if pdf_file.exists() and not target_pdf.exists():
            shutil.copy2(pdf_file, target_pdf)
            print(f"âœ… å¤åˆ¶: {pdf_file.name} -> {target_pdf}")
        
        if md_file.exists() and not target_md.exists():
            shutil.copy2(md_file, target_md)
            print(f"âœ… å¤åˆ¶: {md_file.name} -> {target_md}")
        
        if csv_file.exists() and not target_csv.exists():
            shutil.copy2(csv_file, target_csv)
            print(f"âœ… å¤åˆ¶: {csv_file.name} -> {target_csv}")
        
        # æ­¥éª¤6: åˆå¹¶æ•°æ®åˆ°ä¸»æ–‡ä»¶
        print(f"\nğŸ“Š åˆå¹¶æ•°æ®åˆ°ä¸»æ–‡ä»¶...")
        if not merge_to_main_data(target_csv, args.all_csv, args.covid_csv):
            print(f"âš ï¸  æ•°æ®åˆå¹¶å¤±è´¥")
            continue
        
        print(f"\nâœ… URL {idx}/{len(urls)} å¤„ç†å®Œæˆ!")
    
    print(f"\n{'='*60}")
    print(f"ğŸ‰ å…¨éƒ¨å¤„ç†å®Œæˆ!")
    print(f"{'='*60}")
    print(f"ğŸ“ æ›´æ–°ç›®å½•: {update_dir}")
    print(f"ğŸ“Š å…¨éƒ¨æ•°æ®: {args.all_csv}")
    print(f"ğŸ“Š æ–°å† æ•°æ®: {args.covid_csv}")
    
    return 0


if __name__ == "__main__":
    sys.exit(main())

